"""
Test Board Perspective and Reward System

This test suite verifies the critical fixes for self-play training:
1. Board perspective: Agent always sees its pieces in Channel 0
2. Rewards: Always from moving player's perspective (+1 win, -1 loss, 0 draw)
3. Winning moves: Correctly identified and rewarded
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

import numpy as np
from environment import ConnectFourEnvironment, Config


def print_board(board, title="Board"):
    """Print a visual representation of the board with row numbers."""
    import sys
    sys.stdout.write(f"\n{title}:\n")
    sys.stdout.write("    " + " ".join(str(i) for i in range(7)) + "\n")
    for row in range(6):
        row_str = f"{row} | "
        for col in range(7):
            if board[row, col] == 1:
                row_str += "X "
            elif board[row, col] == -1:
                row_str += "O "
            else:
                row_str += ". "
        sys.stdout.write(row_str + "\n")
    sys.stdout.write("\n")
    sys.stdout.flush()


def test_board_perspective():
    """Test that board perspective is correct for both players."""
    print("\n" + "="*80)
    print("TEST 1: Board Perspective")
    print("="*80)
    
    config = Config()
    env = ConnectFourEnvironment(config)
    
    # Player 1 makes a move
    env.reset()
    state_p1 = env.get_state()
    env.play_move(3)  # Player 1 plays column 3
    
    print("\n‚úì Player 1 made move in column 3")
    print(f"  Current player: {env.current_player}")
    
    # Get state from Player 1's perspective
    state_from_p1 = env.get_state_from_perspective(1)
    print(f"\n  Player 1's perspective:")
    print(f"    Channel 0 (my pieces) has pieces: {np.any(state_from_p1[0] == 1.0)}")
    print(f"    Channel 1 (opponent) has pieces: {np.any(state_from_p1[1] == 1.0)}")
    
    # Get state from Player 2's perspective  
    state_from_p2 = env.get_state_from_perspective(-1)
    print(f"\n  Player 2's perspective:")
    print(f"    Channel 0 (my pieces) has pieces: {np.any(state_from_p2[0] == 1.0)}")
    print(f"    Channel 1 (opponent) has pieces: {np.any(state_from_p2[1] == 1.0)}")
    
    # Verify: Player 1's pieces should be in Channel 0 for P1, Channel 1 for P2
    assert np.any(state_from_p1[0] == 1.0), "Player 1 should see own pieces in Channel 0"
    assert not np.any(state_from_p1[1] == 1.0), "Player 1 should see no opponent pieces yet"
    
    assert not np.any(state_from_p2[0] == 1.0), "Player 2 should see no own pieces yet"
    assert np.any(state_from_p2[1] == 1.0), "Player 2 should see opponent pieces in Channel 1"
    
    print("\n‚úÖ Board perspective test PASSED!")
    print("   - Each player sees own pieces in Channel 0")
    print("   - Each player sees opponent pieces in Channel 1")
    
    return True


def test_reward_perspective():
    """Test that rewards are from moving player's perspective."""
    print("\n" + "="*80)
    print("TEST 2: Reward Perspective")
    print("="*80)
    
    config = Config()
    env = ConnectFourEnvironment(config)
    
    # Create a winning position for Player 1
    # Player 1 (X) can win by playing column 3
    # . . . . . . .
    # . . . . . . .
    # . . . . . . .
    # . . . . . . .
    # . . . . . . .
    # X X X . O O O
    
    env.reset()
    env.board[5, 0] = 1  # Player 1
    env.board[5, 1] = 1  # Player 1
    env.board[5, 2] = 1  # Player 1
    env.board[5, 4] = -1  # Player 2
    env.board[5, 5] = -1  # Player 2
    env.board[5, 6] = -1  # Player 2
    env.current_player = 1
    
    print("\n‚úì Set up winning position for Player 1")
    print("  Board (bottom row): X X X . O O O")
    print("  Player 1 can win by playing column 3")
    
    # Player 1 makes winning move
    state, reward, done = env.play_move(3)
    
    print(f"\n‚úì Player 1 played winning move")
    print(f"  Reward: {reward}")
    print(f"  Done: {done}")
    print(f"  Winner: {env.check_winner()}")
    
    assert done, "Game should be done after winning move"
    assert reward == 1.0, f"Player 1 should get +1.0 reward for winning, got {reward}"
    
    print("\n‚úÖ Reward perspective test PASSED!")
    print("   - Winning player gets +1.0 reward")
    
    return True


def test_losing_perspective():
    """Test that losing player would get -1.0 if they could observe."""
    print("\n" + "="*80)
    print("TEST 3: Losing Perspective (Conceptual)")
    print("="*80)
    
    config = Config()
    env = ConnectFourEnvironment(config)
    
    # Create position where Player 2 is about to lose
    env.reset()
    env.board[5, 0] = 1
    env.board[5, 1] = 1
    env.board[5, 2] = 1
    env.current_player = 1
    
    print("\n‚úì Set up position where Player 1 will win")
    
    # Player 1 wins
    state_before = env.get_state_from_perspective(-1)  # Player 2's view before loss
    state, reward, done = env.play_move(3)
    
    print(f"  Player 1 wins with reward: {reward}")
    print(f"  Player 2 would observe this as a loss")
    
    # In actual training, Player 2 would store:
    # (state_before, their_last_action, -1.0, state_after, done=True)
    # But that happens in the training loop, not in play_move()
    
    assert reward == 1.0, "Winner gets +1.0"
    
    print("\n‚úÖ Losing perspective test PASSED!")
    print("   - In training, opponent will learn from -1.0 reward")
    
    return True


def test_winning_move_detection():
    """Test different winning positions with visual output."""
    print("\n" + "="*80)
    print("TEST 4: Winning Move Detection (14 positions)")
    print("="*80)
    
    config = Config()
    
    test_cases = [
        # (board_setup, winning_column, description)
        ([(5,0,1), (5,1,1), (5,2,1)], 3, "Horizontal win (bottom row)"),
        ([(5,3,1), (4,3,1), (3,3,1)], 3, "Vertical win (column 3)"),
        ([(5,2,1), (5,3,1), (5,4,1)], 5, "Horizontal win (middle)"),
        ([(5,0,1), (4,0,1), (3,0,1)], 0, "Vertical win (column 0)"),
        ([(5,3,1), (5,4,1), (5,5,1)], 6, "Horizontal win (right)"),
        ([(5,6,1), (5,5,1), (5,4,1)], 3, "Horizontal win (right side)"),
        ([(5,1,1), (5,2,1), (5,3,1)], 4, "Horizontal win (left-mid)"),
        ([(5,4,1), (5,5,1), (5,6,1)], 3, "Horizontal win (right-mid)"),
        ([(5,1,1), (4,1,1), (3,1,1)], 1, "Vertical win (column 1)"),
        ([(5,5,1), (4,5,1), (3,5,1)], 5, "Vertical win (column 5)"),
        # Diagonal tests - need support pieces for gravity
        ([(5,0,1), (5,1,-1), (4,1,1), (5,2,-1), (4,2,-1), (3,2,1), (5,3,-1), (4,3,-1), (3,3,-1)], 3, "Diagonal win (ascending left)"),
        ([(5,3,1), (5,4,-1), (4,4,1), (5,5,-1), (4,5,-1), (3,5,1), (5,6,-1), (4,6,-1), (3,6,-1)], 6, "Diagonal win (ascending right)"),
        # Diagonal with continuous pieces - X at (5,0), (4,1), (3,2), needs (2,3) to complete
        ([(5,0,1), (5,1,-1), (4,1,1), (5,2,-1), (4,2,-1), (3,2,1), (5,3,-1), (4,3,-1), (3,3,-1)], 3, "Diagonal continuous (X at 5,0 4,1 3,2, needs 2,3)"),
        # TRUE diagonal with hole - X at (5,1), (4,2), (2,4) with EMPTY at (3,3), needs to fill (3,3)
        # Need support pieces: col 1 up to row 5, col 2 up to row 4, col 3 up to row 2 (NOT 3!), col 4 up to row 2
        # This creates: X at 5,1 | X at 4,2 | HOLE at 3,3 | X at 2,4
        ([(5,1,1), (5,2,-1), (4,2,1), (5,3,-1), (4,3,-1), (5,4,-1), (4,4,-1), (3,4,-1), (2,4,1)], 3, "Diagonal with HOLE (X at 5,1 4,2 2,4, EMPTY at 3,3)"),
    ]
    
    passed = 0
    for i, (setup, win_col, desc) in enumerate(test_cases, 1):
        env = ConnectFourEnvironment(config)
        env.reset()
        
        # Set up board
        for row, col, player in setup:
            env.board[row, col] = player
        
        env.current_player = 1
        
        # Print board BEFORE winning move
        print(f"\n{'‚îÄ'*60}")
        print(f"Test {i}: {desc}")
        print(f"{'‚îÄ'*60}")
        print_board(env.board, f"BEFORE winning move (column {win_col})")
        
        # Make winning move
        try:
            state, reward, done = env.play_move(win_col)
            
            # Print board AFTER winning move
            print_board(env.board, f"AFTER winning move")
            
            if done and reward == 1.0:
                print(f"‚úì Result: PASSED (reward={reward}, done={done})")
                passed += 1
            else:
                print(f"‚úó Result: FAILED (done={done}, reward={reward})")
        except Exception as e:
            print(f"‚úó Result: ERROR - {e}")
    
    print(f"\n{'='*80}")
    print(f"‚úÖ Winning move detection: {passed}/{len(test_cases)} tests passed")
    print(f"{'='*80}")
    assert passed == len(test_cases), f"Expected {len(test_cases)}/{len(test_cases)}, got {passed}/{len(test_cases)}"
    
    return True


def test_draw_scenario():
    """Test that draws give 0.0 reward."""
    print("\n" + "="*80)
    print("TEST 5: Draw Scenario")
    print("="*80)
    
    config = Config()
    env = ConnectFourEnvironment(config)
    env.reset()
    
    # Fill board without winner (simplified test - just fill top row)
    # In reality, need to ensure no 4-in-a-row
    for col in range(7):
        for row in range(6):
            env.board[row, col] = 1 if (row + col) % 2 == 0 else -1
    
    # Make sure no winner
    env.last_move = (0, 0)
    winner = env.check_winner()
    
    if winner is None:
        legal_moves = env.get_legal_moves()
        print(f"\n‚úì Board filled, no winner")
        print(f"  Legal moves: {legal_moves}")
        print(f"  Should be draw")
        
        if len(legal_moves) == 0:
            print("\n‚úÖ Draw scenario test PASSED!")
            print("   - Full board with no winner = draw")
            return True
    
    print("\n‚ö†Ô∏è  Draw test skipped (board has winner or moves available)")
    return True


def main():
    """Run all tests."""
    print("="*80)
    print("PERSPECTIVE AND REWARD SYSTEM TESTS")
    print("="*80)
    print("\nThese tests verify the critical fixes for self-play training:")
    print("1. Board perspective is correct for both players")
    print("2. Rewards are always from moving player's perspective")
    print("3. Winning moves are correctly detected and rewarded")
    
    tests = [
        test_board_perspective,
        test_reward_perspective,
        test_losing_perspective,
        test_winning_move_detection,
        test_draw_scenario,
    ]
    
    passed = 0
    for test in tests:
        try:
            if test():
                passed += 1
        except AssertionError as e:
            print(f"\n‚ùå TEST FAILED: {e}")
        except Exception as e:
            print(f"\n‚ùå TEST ERROR: {e}")
    
    print("\n" + "="*80)
    print(f"FINAL RESULTS: {passed}/{len(tests)} tests passed")
    print("="*80)
    
    if passed == len(tests):
        print("\nüéâ ALL TESTS PASSED! Critical fixes are working correctly.")
        return 0
    else:
        print(f"\n‚ùå {len(tests) - passed} tests failed. Please review and fix.")
        return 1


if __name__ == "__main__":
    exit(main())